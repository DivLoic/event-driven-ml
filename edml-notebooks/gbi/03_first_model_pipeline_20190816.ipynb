{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['dayofweek', 'hourofday', 'pickup_location_id', 'dropoff_location_id', 'trip_duration']\n",
    "LABEL_COLUMN = \"trip_duration\"\n",
    "DEFAULTS = [[1], [0], [0], [0],  []]\n",
    "\n",
    "# DEFAULTS = [\n",
    "#     tf.constant([1], dtype=tf.int64, name=\"dayofweek\"),\n",
    "#     tf.constant([0], dtype=tf.int64, name=\"hourofday\"), \n",
    "#     tf.constant([0], dtype=tf.int64, name=\"pickup_location_id\"), \n",
    "#     tf.constant([0], dtype=tf.int64, name=\"dropoff_location_id\"),\n",
    "#     tf.constant([], dtype=tf.int64, name=\"trip_duration\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "    def _input_fn():\n",
    "        def decode_csv(records):\n",
    "            columns = tf.decode_csv(records, record_defaults=DEFAULTS)\n",
    "            features = dict(zip(CSV_COLUMNS, columns))\n",
    "            label = features.pop(LABEL_COLUMN)\n",
    "            return features, label\n",
    "        \n",
    "        # Create list of files that match pattern\n",
    "        file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "        # Create dataset from file list\n",
    "        dataset = (tf.data.TextLineDataset(file_list,compression_type=\"GZIP\")  # Read text file\n",
    "                   .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
    "\n",
    "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "            num_epochs = None # indefinitely\n",
    "            dataset = dataset.shuffle(buffer_size=10*batch_size, seed=42)\n",
    "        else:\n",
    "            num_epochs = 1 # end-of-input after this\n",
    "\n",
    "        dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "        return dataset\n",
    "    return _input_fn\n",
    "\n",
    "def get_train_input_fn():\n",
    "    return read_dataset('gs://edml/data/taxi-trips/train/tlc_yellow_trips_2018-000*.csv',\n",
    "                        mode = tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid_input_fn():\n",
    "    return read_dataset('gs://edml/data/taxi-trips/val/tlc_yellow_trips_2018-000*.csv',\n",
    "                        mode = tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wide_deep():\n",
    "    \n",
    "#     features[\"dayofweek\"] = features[\"dayofweek\"] - 1\n",
    "    \n",
    "    # One hot encode categorical features\n",
    "    fc_dayofweek = tf.feature_column.categorical_column_with_identity(key=\"dayofweek\", num_buckets = 7)\n",
    "    fc_hourofday = tf.feature_column.categorical_column_with_identity(key=\"hourofday\", num_buckets = 24)\n",
    "    fc_pickuploc = tf.feature_column.categorical_column_with_identity(key=\"pickup_location_id\", num_buckets = 264)\n",
    "    fc_dropoffloc = tf.feature_column.categorical_column_with_identity(key=\"dropoff_location_id\", num_buckets = 264)\n",
    "    \n",
    "    # Cross features to get combination of day and hour and pickup-dropoff locations\n",
    "    fc_crossed_day_hr = tf.feature_column.crossed_column(keys = [fc_dayofweek, fc_hourofday], hash_bucket_size = 24 * 7)\n",
    "    fc_crossed_pd_pair = tf.feature_column.crossed_column(keys = [fc_pickuploc, fc_dropoffloc], hash_bucket_size = 264*264)\n",
    "    \n",
    "    wide = [\n",
    "        # Feature crosses\n",
    "        fc_crossed_day_hr, fc_crossed_pd_pair,\n",
    "        \n",
    "        # Sparse columns\n",
    "        fc_dayofweek, fc_hourofday,\n",
    "        fc_pickuploc, fc_dropoffloc\n",
    "    ]\n",
    "    \n",
    "    # Embedding_column to \"group\" together ...\n",
    "    fc_embed_pd_pair = tf.feature_column.embedding_column(categorical_column = fc_crossed_pd_pair, dimension = 4)\n",
    "    fc_embed_day_hr = tf.feature_column.embedding_column(categorical_column = fc_crossed_day_hr, dimension = 16)\n",
    "    \n",
    "    deep = [\n",
    "        fc_embed_pd_pair,\n",
    "        fc_embed_day_hr\n",
    "    ]\n",
    "    \n",
    "    return wide, deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEAT_COLUMNS = [\n",
    "#     tf.feature_column.categorical_column_with_identity(key = \"dayofweek\", num_buckets = 7),\n",
    "#     tf.feature_column.categorical_column_with_identity(key = \"hourofday\", num_buckets = 24),\n",
    "#     tf.feature_column.categorical_column_with_identity('pickup_location_id', num_buckets = 264),\n",
    "#     tf.feature_column.categorical_column_with_identity('dropoff_location_id', num_buckets = 264)\n",
    "# ]\n",
    "\n",
    "# def basic_feat_eng(feats):\n",
    "#     feats[\"day_hour\"] = tf.feature_column.crossed_column(keys = [\"dayofweek\", \"hourofday\"], hash_bucket_size = 24 * 7)\n",
    "#     feats[\"pickup_dropoff_loc\"] = tf.feature_column.crossed_column(keys = [\"pickup_location_id\", \"dropoff_location_id\"], \n",
    "#                                                                    hash_bucket_size = 264 * 264)\n",
    "#     return feats\n",
    "\n",
    "# feature_cols = basic_feat_eng(FEAT_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serving input receiver function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function to be able to serve predictions later using provided inputs\n",
    "\n",
    "def serving_input_receiver_fn():\n",
    "    receiver_tensors = {\n",
    "        'dayofweek' : tf.placeholder(dtype = tf.int64, shape = [None], name=\"dayofweek\"),\n",
    "        'hourofday' : tf.placeholder(dtype = tf.int64, shape = [None], name=\"hourofday\"),\n",
    "        'pickup_location_id' : tf.placeholder(dtype = tf.int64, shape = [None], name=\"pickup_location_id\"), \n",
    "        'dropoff_location_id' : tf.placeholder(dtype = tf.int64, shape = [None], name=\"dropoff_location_id\"),\n",
    "    }\n",
    "    \n",
    "    features = {\n",
    "        key: tf.expand_dims(tensor, -1)\n",
    "        for key, tensor in receiver_tensors.items()\n",
    "    }\n",
    "        \n",
    "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = receiver_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "    \n",
    "    EVAL_INTERVAL = 300\n",
    "    wide, deep = get_wide_deep()\n",
    "    \n",
    "    run_config = tf.estimator.RunConfig(save_checkpoints_secs = EVAL_INTERVAL,\n",
    "                                        tf_random_seed = 42,\n",
    "                                        keep_checkpoint_max = 3)\n",
    "    \n",
    "    # Add custom evaluation metric\n",
    "    def my_rmse(labels, predictions):\n",
    "        pred_values = tf.squeeze(input = predictions[\"predictions\"], axis = -1)\n",
    "        return {\"rmse\": tf.metrics.root_mean_squared_error(labels = labels, predictions = pred_values)}\n",
    "    \n",
    "    estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "        model_dir = output_dir,\n",
    "        linear_feature_columns = wide,\n",
    "        dnn_feature_columns = deep,\n",
    "        dnn_hidden_units = [128, 64, 32],\n",
    "        config = run_config)\n",
    "    \n",
    "    estimator = tf.contrib.estimator.add_metrics(estimator = estimator, metric_fn = my_rmse) \n",
    "    \n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = get_train_input_fn(),\n",
    "        max_steps = 500)\n",
    "    \n",
    "    exporter = tf.estimator.LatestExporter('exporter', serving_input_receiver_fn = serving_input_receiver_fn)\n",
    "    \n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        input_fn = get_valid_input_fn(),\n",
    "        steps = None,\n",
    "        start_delay_secs = 60, # start evaluating after N seconds\n",
    "        throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "        exporters = exporter)\n",
    "    \n",
    "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0821 17:30:10.037065 140085705914112 estimator.py:209] Using config: {'_save_summary_steps': 100, '_keep_checkpoint_max': 3, '_save_checkpoints_secs': 300, '_save_checkpoints_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_protocol': None, '_tf_random_seed': 42, '_service': None, '_num_worker_replicas': 1, '_device_fn': None, '_experimental_distribute': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_is_chief': True, '_train_distribute': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_global_id_in_cluster': 0, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67c81704a8>, '_model_dir': 'gs://edml/data/taxi-trips/model', '_num_ps_replicas': 0, '_eval_distribute': None}\n",
      "I0821 17:30:10.039213 140085705914112 estimator.py:209] Using config: {'_save_summary_steps': 100, '_keep_checkpoint_max': 3, '_save_checkpoints_secs': 300, '_save_checkpoints_steps': None, '_experimental_max_worker_delay_secs': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_protocol': None, '_tf_random_seed': 42, '_service': None, '_num_worker_replicas': 1, '_device_fn': None, '_experimental_distribute': None, '_log_step_count_steps': 100, '_task_type': 'worker', '_is_chief': True, '_train_distribute': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_global_id_in_cluster': 0, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f67c8170588>, '_model_dir': 'gs://edml/data/taxi-trips/model', '_num_ps_replicas': 0, '_eval_distribute': None}\n",
      "I0821 17:30:10.040523 140085705914112 estimator_training.py:186] Not using Distribute Coordinator.\n",
      "I0821 17:30:10.041519 140085705914112 training.py:612] Running training and evaluation locally (non-distributed).\n",
      "I0821 17:30:10.042530 140085705914112 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "I0821 17:30:10.250135 140085705914112 estimator.py:1145] Calling model_fn.\n",
      "I0821 17:30:10.252419 140085705914112 estimator.py:1145] Calling model_fn.\n",
      "I0821 17:30:12.116728 140085705914112 estimator.py:1147] Done calling model_fn.\n",
      "I0821 17:30:12.118103 140085705914112 estimator.py:1147] Done calling model_fn.\n",
      "I0821 17:30:12.119628 140085705914112 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0821 17:30:13.723446 140085705914112 monitored_session.py:240] Graph was finalized.\n",
      "I0821 17:30:14.123937 140085705914112 session_manager.py:500] Running local_init_op.\n",
      "I0821 17:30:14.164623 140085705914112 session_manager.py:502] Done running local_init_op.\n",
      "I0821 17:30:16.030944 140085705914112 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://edml/data/taxi-trips/model/model.ckpt.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "assertion failed: [1 7 2...] [7]\n\t [[node dnn/input_from_feature_columns/input_layer/dayofweek_X_hourofday_embedding/assert_less_than_num_buckets/Assert/AssertGuard/Assert (defined at /tmp/tmpre2nggm4.py:51) ]]\n\nOriginal stack trace for 'dnn/input_from_feature_columns/input_layer/dayofweek_X_hourofday_embedding/assert_less_than_num_buckets/Assert/AssertGuard/Assert':\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-a19e4eaceea6>\", line 6, in <module>\n    train_and_evaluate(OUTDIR)\n  File \"<ipython-input-6-18528fde9d40>\", line 38, in train_and_evaluate\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n    return executor.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n    return self.run_local()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n    saving_listeners=saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/extenders.py\", line 89, in new_model_fn\n    spec = estimator.model_fn(features, labels, mode, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 247, in public_model_fn\n    return self._call_model_fn(features, labels, mode, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\", line 1146, in _model_fn\n    linear_sparse_combiner=linear_sparse_combiner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\", line 343, in _dnn_linear_combined_model_fn\n    dnn_logits = dnn_logit_fn(features=features, mode=mode)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 107, in dnn_logit_fn\n    return dnn_model(features, mode)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 450, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/tmp/tmp23y35y0o.py\", line 15, in tf__call\n    net = ag__.converted_call('_input_layer', self, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (features,), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 356, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in _call_unconverted\n    return f(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 450, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/tmp/tmpre2nggm4.py\", line 70, in tf__call\n    ag__.for_stmt(self._feature_columns, None, loop_body, ())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 110, in for_stmt\n    return _py_for_stmt(iter_, extra_test, body, init_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 119, in _py_for_stmt\n    state = body(target, *state)\n  File \"/tmp/tmpre2nggm4.py\", line 51, in loop_body\n    tensor = ag__.converted_call('get_dense_tensor', column, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (transformation_cache, self._state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 356, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in _call_unconverted\n    return f(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3121, in get_dense_tensor\n    transformation_cache, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 4084, in get_sparse_tensors\n    transformation_cache.get(self, state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2562, in get\n    transformed = column.transform_feature(self, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 4033, in transform_feature\n    state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3830, in get_sparse_tensors\n    transformation_cache.get(self, state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2562, in get\n    transformed = column.transform_feature(self, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3808, in transform_feature\n    return self._transform_input_tensor(input_tensor)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3783, in _transform_input_tensor\n    name='assert_less_than_num_buckets')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py\", line 862, in assert_less\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 171, in Assert\n    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1988, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1814, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 169, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 74, in _assert\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [1 7 2...] [7]\n\t [[{{node dnn/input_from_feature_columns/input_layer/dayofweek_X_hourofday_embedding/assert_less_than_num_buckets/Assert/AssertGuard/Assert}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a19e4eaceea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# so loss is printed during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTDIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-18528fde9d40>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(output_dir)\u001b[0m\n\u001b[1;32m     36\u001b[0m         exporters = exporter)\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    471\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    611\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    612\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;31m# Distributed case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m     eval_result = listener_for_eval.eval_result or _EvalResult(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1191\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many_step_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m             run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1253\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         logging.info(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1336\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1339\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: assertion failed: [1 7 2...] [7]\n\t [[node dnn/input_from_feature_columns/input_layer/dayofweek_X_hourofday_embedding/assert_less_than_num_buckets/Assert/AssertGuard/Assert (defined at /tmp/tmpre2nggm4.py:51) ]]\n\nOriginal stack trace for 'dnn/input_from_feature_columns/input_layer/dayofweek_X_hourofday_embedding/assert_less_than_num_buckets/Assert/AssertGuard/Assert':\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-a19e4eaceea6>\", line 6, in <module>\n    train_and_evaluate(OUTDIR)\n  File \"<ipython-input-6-18528fde9d40>\", line 38, in train_and_evaluate\n    tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n    return executor.run()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n    return self.run_local()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n    saving_listeners=saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1188, in _train_model_default\n    features, labels, ModeKeys.TRAIN, self.config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/contrib/estimator/python/estimator/extenders.py\", line 89, in new_model_fn\n    spec = estimator.model_fn(features, labels, mode, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 247, in public_model_fn\n    return self._call_model_fn(features, labels, mode, config)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1146, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\", line 1146, in _model_fn\n    linear_sparse_combiner=linear_sparse_combiner)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\", line 343, in _dnn_linear_combined_model_fn\n    dnn_logits = dnn_logit_fn(features=features, mode=mode)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/dnn.py\", line 107, in dnn_logit_fn\n    return dnn_model(features, mode)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 450, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/tmp/tmp23y35y0o.py\", line 15, in tf__call\n    net = ag__.converted_call('_input_layer', self, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (features,), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 356, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in _call_unconverted\n    return f(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\", line 634, in __call__\n    outputs = call_fn(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 146, in wrapper\n    ), args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 450, in converted_call\n    result = converted_f(*effective_args, **kwargs)\n  File \"/tmp/tmpre2nggm4.py\", line 70, in tf__call\n    ag__.for_stmt(self._feature_columns, None, loop_body, ())\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 110, in for_stmt\n    return _py_for_stmt(iter_, extra_test, body, init_state)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 119, in _py_for_stmt\n    state = body(target, *state)\n  File \"/tmp/tmpre2nggm4.py\", line 51, in loop_body\n    tensor = ag__.converted_call('get_dense_tensor', column, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (transformation_cache, self._state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 356, in converted_call\n    return _call_unconverted(f, args, kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/autograph/impl/api.py\", line 255, in _call_unconverted\n    return f(*args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3121, in get_dense_tensor\n    transformation_cache, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 4084, in get_sparse_tensors\n    transformation_cache.get(self, state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2562, in get\n    transformed = column.transform_feature(self, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 4033, in transform_feature\n    state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3830, in get_sparse_tensors\n    transformation_cache.get(self, state_manager), None)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 2562, in get\n    transformed = column.transform_feature(self, state_manager)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3808, in transform_feature\n    return self._transform_input_tensor(input_tensor)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/feature_column/feature_column_v2.py\", line 3783, in _transform_input_tensor\n    name='assert_less_than_num_buckets')\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/check_ops.py\", line 862, in assert_less\n    return control_flow_ops.Assert(condition, data, summarize=summarize)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py\", line 193, in wrapped\n    return _add_should_use_warning(fn(*args, **kwargs))\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 171, in Assert\n    guarded_assert = cond(condition, no_op, true_assert, name=\"AssertGuard\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1988, in cond\n    orig_res_f, res_f = context_f.BuildCondBranch(false_fn)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1814, in BuildCondBranch\n    original_result = fn()\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 169, in true_assert\n    condition, data, summarize, name=\"Assert\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_logging_ops.py\", line 74, in _assert\n    name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = \"gs://edml/data/taxi-trips/model\"\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "tf.logging.set_verbosity(v = tf.logging.INFO) # so loss is printed during training\n",
    "\n",
    "train_and_evaluate(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
