{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = 'gs://edml'\n",
    "os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training / Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer\n",
    "echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-22 16:44:56.448098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_trained_test', '_tf_random_seed': 2810, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29e96a7c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_trained_test', '_tf_random_seed': 2810, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29e96a7c50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_trained_test', '_tf_random_seed': 2810, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29c60d6490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_trained_test', '_tf_random_seed': 2810, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 300, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 3, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f29c60d6490>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_io/bigquery/python/ops/bigquery_api.py:214: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_io/bigquery/python/ops/bigquery_api.py:214: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:305: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:3079: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-04-22 16:45:04.819322: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
      "2020-04-22 16:45:04.820808: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4afe07ca0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-22 16:45:04.820849: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-22 16:45:04.825136: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-04-22 16:45:06.897948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:06.898581: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4b09c40f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-22 16:45:06.898623: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2020-04-22 16:45:06.898970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:06.899445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-04-22 16:45:06.899501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-22 16:45:07.002640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-22 16:45:07.048397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-22 16:45:07.066931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-22 16:45:07.180318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-22 16:45:07.248701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-22 16:45:07.430152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-22 16:45:07.430458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:07.431008: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:07.431387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-04-22 16:45:07.434073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-22 16:45:09.843733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-22 16:45:09.843795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-04-22 16:45:09.843823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-04-22 16:45:09.845484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:09.846020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:09.846446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_trained_test/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_trained_test/model.ckpt.\n",
      "2020-04-22 16:45:13.530353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-22 16:45:24.298460: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:145] Filling up shuffle buffer (this may take a while): 112056 of 128000\n",
      "2020-04-22 16:45:25.496360: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:195] Shuffle buffer filled.\n",
      "INFO:tensorflow:loss = 2118141.0, step = 0\n",
      "INFO:tensorflow:loss = 2118141.0, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 100 into model_trained_test/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into model_trained_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-22T16:45:30Z\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-22T16:45:30Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2020-04-22 16:45:30.533007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:30.533305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-04-22 16:45:30.533352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-22 16:45:30.533435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-22 16:45:30.533475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-22 16:45:30.533506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-22 16:45:30.533545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-22 16:45:30.533577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-22 16:45:30.533617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-22 16:45:30.533701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:30.534030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:30.534271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-04-22 16:45:30.534323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-22 16:45:30.534346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-04-22 16:45:30.534353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-04-22 16:45:30.534553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:30.534846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:30.535119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/2]\n",
      "INFO:tensorflow:Evaluation [1/2]\n",
      "INFO:tensorflow:Evaluation [2/2]\n",
      "INFO:tensorflow:Evaluation [2/2]\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-22-16:45:40\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-22-16:45:40\n",
      "INFO:tensorflow:Saving dict for global step 100: average_loss = 4675.965, global_step = 100, label/mean = 18.155334, loss = 153222020.0, prediction/mean = 1.8246641, rmse = 68.38103\n",
      "INFO:tensorflow:Saving dict for global step 100: average_loss = 4675.965, global_step = 100, label/mean = 18.155334, loss = 153222020.0, prediction/mean = 1.8246641, rmse = 68.38103\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:Signatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'dayofweek:0' shape=(?,) dtype=int64>, 'hourofday': <tf.Tensor 'hourofday:0' shape=(?,) dtype=int64>, 'weekofyear': <tf.Tensor 'weekofyear:0' shape=(?,) dtype=int64>, 'pickup_zone_name': <tf.Tensor 'pickup_zone_name:0' shape=(?,) dtype=string>, 'dropoff_zone_name': <tf.Tensor 'dropoff_zone_name:0' shape=(?,) dtype=string>, 'passenger_count': <tf.Tensor 'passenger_count:0' shape=(?,) dtype=int64>, 'distance': <tf.Tensor 'distance:0' shape=(?,) dtype=float64>, 'uuid': <tf.Tensor 'uuid:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'serving_default' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'dayofweek:0' shape=(?,) dtype=int64>, 'hourofday': <tf.Tensor 'hourofday:0' shape=(?,) dtype=int64>, 'weekofyear': <tf.Tensor 'weekofyear:0' shape=(?,) dtype=int64>, 'pickup_zone_name': <tf.Tensor 'pickup_zone_name:0' shape=(?,) dtype=string>, 'dropoff_zone_name': <tf.Tensor 'dropoff_zone_name:0' shape=(?,) dtype=string>, 'passenger_count': <tf.Tensor 'passenger_count:0' shape=(?,) dtype=int64>, 'distance': <tf.Tensor 'distance:0' shape=(?,) dtype=float64>, 'uuid': <tf.Tensor 'uuid:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'dayofweek:0' shape=(?,) dtype=int64>, 'hourofday': <tf.Tensor 'hourofday:0' shape=(?,) dtype=int64>, 'weekofyear': <tf.Tensor 'weekofyear:0' shape=(?,) dtype=int64>, 'pickup_zone_name': <tf.Tensor 'pickup_zone_name:0' shape=(?,) dtype=string>, 'dropoff_zone_name': <tf.Tensor 'dropoff_zone_name:0' shape=(?,) dtype=string>, 'passenger_count': <tf.Tensor 'passenger_count:0' shape=(?,) dtype=int64>, 'distance': <tf.Tensor 'distance:0' shape=(?,) dtype=float64>, 'uuid': <tf.Tensor 'uuid:0' shape=(?,) dtype=string>}\n",
      "INFO:tensorflow:'regression' : Regression input must be a single string Tensor; got {'dayofweek': <tf.Tensor 'dayofweek:0' shape=(?,) dtype=int64>, 'hourofday': <tf.Tensor 'hourofday:0' shape=(?,) dtype=int64>, 'weekofyear': <tf.Tensor 'weekofyear:0' shape=(?,) dtype=int64>, 'pickup_zone_name': <tf.Tensor 'pickup_zone_name:0' shape=(?,) dtype=string>, 'dropoff_zone_name': <tf.Tensor 'dropoff_zone_name:0' shape=(?,) dtype=string>, 'passenger_count': <tf.Tensor 'passenger_count:0' shape=(?,) dtype=int64>, 'distance': <tf.Tensor 'distance:0' shape=(?,) dtype=float64>, 'uuid': <tf.Tensor 'uuid:0' shape=(?,) dtype=string>}\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "2020-04-22 16:45:42.269475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:42.269806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "2020-04-22 16:45:42.269872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-22 16:45:42.269967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-22 16:45:42.270035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-22 16:45:42.270103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-22 16:45:42.270172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-22 16:45:42.270235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-22 16:45:42.270304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-22 16:45:42.270438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:42.270787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:42.271071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
      "2020-04-22 16:45:42.271122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-22 16:45:42.271139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
      "2020-04-22 16:45:42.271153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
      "2020-04-22 16:45:42.271360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:42.271698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-22 16:45:42.271966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10747 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "INFO:tensorflow:Restoring parameters from model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Restoring parameters from model_trained_test/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: model_trained_test/export/exporter/temp-b'1587573941'/saved_model.pb\n",
      "INFO:tensorflow:SavedModel written to: model_trained_test/export/exporter/temp-b'1587573941'/saved_model.pb\n",
      "INFO:tensorflow:Loss for final step: 25936.203.\n",
      "INFO:tensorflow:Loss for final step: 25936.203.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf model_trained_test\n",
    "export PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer\n",
    "python3 -m trainer.task \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --output-dir=model_trained_test \\\n",
    "  --job-dir=./tmp \\\n",
    "  --train-steps=100 \\\n",
    "  --nembeds 10 \\\n",
    "  --nnsize 10 5 \\\n",
    "  --eval-steps=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile inputs.json\n",
    "{\"uuid\": \"b1\", \"dayofweek\": 6, \"hourofday\": 7, \"weekofyear\": 48, \"pickup_zone_name\": \"World Trade Center\", \"dropoff_zone_name\": \"Newark Airport\", \"passenger_count\": 1, \"distance\": 18000.0}\n",
    "{\"uuid\": \"g1\", \"dayofweek\": 3, \"hourofday\": 23, \"weekofyear\": 27, \"pickup_zone_name\": \"World Trade Center\", \"dropoff_zone_name\": \"Times Sq/Theatre District\", \"passenger_count\": 1, \"distance\": 3400.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had this [issue](https://github.com/GoogleCloudPlatform/cloudml-samples/issues/415). Following instructions from [stackoverflow](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "First run command `gcloud ai-platform local predict` with `--verbosity debug` to find the correct path, then delete `*.pyc` files thes launch local train again.\n",
    "\n",
    "```\n",
    "%%bash\n",
    "sudo find /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine -name '*.pyc' -delete\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_LOCATION=$(ls -d $(pwd)/model_trained_test/export/exporter/* | tail -1)\n",
    "echo $MODEL_LOCATION\n",
    "gcloud ai-platform local predict --model-dir=$MODEL_LOCATION --json-instances=inputs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training / Gcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ai-platform - manage AI Platform jobs and models\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ai-platform GROUP | COMMAND [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    The gcloud ai-platform command group lets you manage AI Platform jobs and\n",
      "    training models.\n",
      "\n",
      "    AI Platform is a managed service that enables you to easily build machine\n",
      "    learning models, that work on any type of data, of any size. Create your\n",
      "    model with the powerful TensorFlow framework that powers many Google\n",
      "    products, from Google Photos to Google Cloud Speech.\n",
      "\n",
      "    More information on AI Platform can be found here:\n",
      "    https://cloud.google.com/ml and detailed documentation can be found here:\n",
      "    https://cloud.google.com/ml/docs/\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --billing-project,\n",
      "    --configuration, --flags-file, --flatten, --format, --help,\n",
      "    --impersonate-service-account, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity.\n",
      "\n",
      "    Run $ gcloud help for details.\n",
      "\n",
      "GROUPS\n",
      "    GROUP is one of the following:\n",
      "\n",
      "     jobs\n",
      "        AI Platform Jobs commands.\n",
      "\n",
      "     local\n",
      "        AI Platform Local commands.\n",
      "\n",
      "     models\n",
      "        AI Platform Models commands.\n",
      "\n",
      "     operations\n",
      "        Manage AI Platform operations.\n",
      "\n",
      "     versions\n",
      "        AI Platform Versions commands.\n",
      "\n",
      "COMMANDS\n",
      "    COMMAND is one of the following:\n",
      "\n",
      "     predict\n",
      "        Run AI Platform online prediction.\n",
      "\n",
      "NOTES\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ai-platform\n",
      "        $ gcloud beta ai-platform\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ai-platform --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    --package-path=~/event-driven-ml/edml-trainer \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ai-platform.local.train] with arguments: [--module-name: \"trainer.task\", --package-path: \"../../edml-trainer/\", --verbosity: \"debug\"]\n",
      "INFO: launching training process:\n",
      "command: /opt/conda/bin/python -m trainer.task --train-steps=1000 --output-dir=model_trained_test --eval-steps=1\n",
      " config: {\n",
      "  \"cluster\": {}, \n",
      "  \"environment\": \"cloud\", \n",
      "  \"job\": {\n",
      "    \"args\": [\n",
      "      \"--train-steps=1000\", \n",
      "      \"--output-dir=model_trained_test\", \n",
      "      \"--eval-steps=1\"\n",
      "    ], \n",
      "    \"job_name\": \"trainer.task\"\n",
      "  }, \n",
      "  \"task\": {}\n",
      "}\n",
      "WARNING: Unexpected tensorflow version 2020-04-22 16:16:08.093465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "1.15.2\n",
      ", using the default primary node name, aka \"chief\" for cluster settings\n",
      "INFO: Display format: \"default\"\n",
      "DEBUG: Exception captured in Commands\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 631, in Wrapper\n",
      "    return func(*args, **kwds)\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 764, in Commands\n",
      "    error_extra_info_json=_GetErrorExtraInfo(error_extra_info))\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 728, in _GetErrorExtraInfo\n",
      "    return json.dumps(error_extra_info, sort_keys=True)\n",
      "  File \"/usr/lib/python2.7/json/__init__.py\", line 251, in dumps\n",
      "    sort_keys=sort_keys, **kw).encode(obj)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 209, in encode\n",
      "    chunks = list(chunks)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 434, in _iterencode\n",
      "    for chunk in _iterencode_dict(o, _current_indent_level):\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 408, in _iterencode_dict\n",
      "    for chunk in chunks:\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 442, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 184, in default\n",
      "    raise TypeError(repr(o) + \" is not JSON serializable\")\n",
      "TypeError: <subprocess.Popen object at 0x7fc771230510> is not JSON serializable\n",
      "DEBUG: Exception captured in Error\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 631, in Wrapper\n",
      "    return func(*args, **kwds)\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 795, in Error\n",
      "    error_extra_info_json=_GetErrorExtraInfo(error_extra_info))\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/core/metrics.py\", line 728, in _GetErrorExtraInfo\n",
      "    return json.dumps(error_extra_info, sort_keys=True)\n",
      "  File \"/usr/lib/python2.7/json/__init__.py\", line 251, in dumps\n",
      "    sort_keys=sort_keys, **kw).encode(obj)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 209, in encode\n",
      "    chunks = list(chunks)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 434, in _iterencode\n",
      "    for chunk in _iterencode_dict(o, _current_indent_level):\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 408, in _iterencode_dict\n",
      "    for chunk in chunks:\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 442, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/usr/lib/python2.7/json/encoder.py\", line 184, in default\n",
      "    raise TypeError(repr(o) + \" is not JSON serializable\")\n",
      "TypeError: <subprocess.Popen object at 0x7fc771230510> is not JSON serializable\n",
      "DEBUG: (gcloud.ai-platform.local.train) \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/calliope/cli.py\", line 983, in Execute\n",
      "    resources = calliope_command.Run(cli=self, args=args)\n",
      "  File \"/usr/lib/google-cloud-sdk/lib/googlecloudsdk/calliope/backend.py\", line 813, in Run\n",
      "    raise exceptions.ExitCodeNoError(exit_code=command_instance.exit_code)\n",
      "ExitCodeNoError\n",
      "<subprocess.Popen object at 0x7fc771230510>\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'rm -rf model_trained_test\\nexport PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer:/usr/bin/python\\ngcloud ai-platform local train \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=../../edml-trainer/ \\\\\\n   --verbosity=debug \\\\\\n   -- \\\\\\n   --train-steps=1000 \\\\\\n   --output-dir=model_trained_test \\\\\\n   --eval-steps=1\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a816f27b317b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rm -rf model_trained_test\\nexport PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer:/usr/bin/python\\ngcloud ai-platform local train \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=../../edml-trainer/ \\\\\\n   --verbosity=debug \\\\\\n   -- \\\\\\n   --train-steps=1000 \\\\\\n   --output-dir=model_trained_test \\\\\\n   --eval-steps=1\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2360\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'rm -rf model_trained_test\\nexport PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer:/usr/bin/python\\ngcloud ai-platform local train \\\\\\n   --module-name=trainer.task \\\\\\n   --package-path=../../edml-trainer/ \\\\\\n   --verbosity=debug \\\\\\n   -- \\\\\\n   --train-steps=1000 \\\\\\n   --output-dir=model_trained_test \\\\\\n   --eval-steps=1\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf model_trained_test\n",
    "export PYTHONPATH=${PYTHONPATH}:~/event-driven-ml/edml-trainer:/usr/bin/python\n",
    "gcloud ai-platform local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=../../edml-trainer/ \\\n",
    "   --verbosity=debug \\\n",
    "   -- \\\n",
    "   --train-steps=1000 \\\n",
    "   --output-dir=model_trained_test \\\n",
    "   --eval-steps=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cp -r ~/event-driven-ml/edml-trainer/* gs://edml/ai-platform/edml-trainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
